



<table>
  <tr>
    <td style="border: none;">
      <img src="profile-pic.jpeg" alt="Your Image" style="border-radius: 100%; margin-right: 20px; width: 150px;">
      <div style="text-align: center;">Joseph Adeola</div>
    </td>
    <td style="border: none;">
       <h1 >üëã Hi there! Welcome to my projects page. </h1>
      <span>Here, you'll find a collection of my work over the past 2 years in robotics ü¶æ, AI üß†, computer vision üëÅÔ∏è, data science üìä, and more. Enjoy exploring! üåü</span>
    </td>
  </tr>
</table>

# üìÇ All Projects

### üö® Confidentiality Notice
Certain parts of the code in these projects are confidential and are not shared publicly. If you have any questions or require access, please contact me directly.


## Sections

- [Robotics and Control](#robotics-and-control)
- [Computer Vision and Image Processing](#computer-vision-and-image-processing)
- [AI and Machine Learning](#ai-and-machine-learning)
- [SLAM and Localization](#slam-and-localization)
- [Motion Planning and Autonomous Systems](#motion-planning-and-autonomous-systems)
- [Multi-Robot Systems and Swarm Robotics](#multi-robot-systems-and-swarm-robotics)


## Robotics and Control

- **[Design of an Attitude and Position PID Controller for a Quadcopter](https://github.com/yourusername/quadcopter-pid-controller)** [![Code](https://img.shields.io/badge/Code-blue)](https://github.com/yourusername/quadcopter-pid-controller) [![Demo](https://img.shields.io/badge/Demo-orange)](https://yourDemo-link.com) [![Paper](https://img.shields.io/badge/Paper-green)](https://yourpaper-link.com) [![Demo](https://img.shields.io/badge/Demo-yellow)](https://yourdemo-link.com):
  
  A PID control system for quadcopter attitude and position control. Implements separate controllers for roll, pitch, yaw, and altitude. Addresses challenges in tuning gains for stable flight in various conditions and disturbance rejection.

- **[Pick and Place Application with the St√§ubli TS60 Industrial Robot](https://github.com/yourusername/staubli-ts60-pick-place)** ![Confidential](https://img.shields.io/badge/Confidential-red) [![Demo](https://img.shields.io/badge/Demo-orange)](https://drive.google.com/file/d/1aKQZmrNwI2H5UhDMYRUBBaicdBn9iq9I/view) [![Report](https://img.shields.io/badge/Report-green)](https://drive.google.com/file/d/1aPR2mKm8HVClOIRoVWpmKaSMeXWIaC-c/view):
  
  A pick and place system implementation in VAL3 language for the **St√§ubli TS60 industrial robot**.

- **[Pick and Place Application with the St√§ubli TX60 Industrial Robot](https://github.com/yourusername/staubli-tx60-pick-place)** ![Confidential](https://img.shields.io/badge/Confidential-red) [![Demo](https://img.shields.io/badge/Demo-orange)](https://drive.google.com/file/d/1aKrhzGyr0Auz40XHXGWk59_aASbLIbHi/view) [![Report](https://img.shields.io/badge/Report-green)](https://drive.google.com/file/d/1aPr91n5oAYynJxZ6tkZL88Wp2k3vadhR/view):
  
  A high-speed pick and place application for the **St√§ubli TX60 industrial robot** in VAL3 language.


- **[Task-Priority Redundancy Resolution Algorithm for a Mobile-base Manipulator Robot](https://github.com/MosesEbere/hands_on_intervention)** [![Move-to-point](https://img.shields.io/badge/Move--to--point-lightblue)](https://drive.google.com/file/d/1kn2_gko-IFSkljblYQMjXANdpQjNa0rN/view) [![Pick-and-place](https://img.shields.io/badge/Pick--and--place-lightblue)](https://drive.google.com/file/d/1KHs2diTsSIVnFagZMXMcA8l_p_WiexcS/view) [![Pick-transport-and-place](https://img.shields.io/badge/Pick--transport--and--place-lightblue)](https://drive.google.com/file/d/1K6A4IXmg--vPBryF4WTcQLSJuJ77wXlQ/view) [![Pick-transport-and-place with Visual Feedback](https://img.shields.io/badge/Pick--transport--and--place%20with%20Visual%20Feedback-lightblue)](https://drive.google.com/file/d/1lAg9mKXbvocwgNylMy-xydm41HCEizhB/view) [![Slides](https://img.shields.io/badge/Slides-yellow)](drive.google.com/file/d/1GWa_pOjubxcN2Xha_cPQEmdidF82-esj/view) [![Paper](https://img.shields.io/badge/Paper-green)](https://drive.google.com/file/d/1zYYLAgOqRJE_yjYbQvPuM748Q1R_CwFf/view):
  
  A task-priority redundancy resolution algorithm for a mobile-base manipulator robot. Focuses on coordinating a mobile base with a robotic arm, implementing multiple task scenarios like move-to-point, pick-and-place, and pick-transport-and-place with visual feedback. Tackles challenges in managing multiple degrees of freedom and avoiding singularities.



- **[Design and Simulation of a SCARA Manipulator in ROS and Gazebo](https://github.com/adeola-jo/SCARA-TS60-Robot-Design-Simulation)**  [![Code](https://img.shields.io/badge/Code-blue)](https://github.com/adeola-jo/SCARA-TS60-Robot-Design-Simulation): 
  
  A model of the St√§ubli TS60 SCARA robot arm modeled from scratch using URDF and simulated in ROS and Gazebo. 

## Computer Vision and Image Processing

- **[Integrated Machine Vision Application with the St√§ubli TX60 Robot](https://github.com/yourusername/staubli-tx60-vision)** ![Confidential](https://img.shields.io/badge/Confidential-red) [![Demo](https://img.shields.io/badge/Demo-orange)](https://drive.google.com/file/d/1Qt3sHE5qjNmcZQxpsC_hMEyIe0jYCMcI/view) [![Report](https://img.shields.io/badge/Report-green)](https://drive.google.com/file/d/1aUCzHSmlDRThpmZoUU5Uk83FfAI0ACnv/view):
  
  A machine vision system integrated with the St√§ubli TX60 robot. Uses ARUCO markers for object detection and pose estimation. 
  <!-- Tackles challenges in real-time processing and robust error handling in dynamic industrial environments. -->

- **[Stereo Visual Odometry on the KITTI Dataset](https://github.com/AdeolaJoseph/Stereo-Visual-Odometry)**:
  
  A stereo visual odometry system using the KITTI dataset. Implements feature extraction, matching, and motion estimation techniques. 
  <!-- Addresses challenges in handling diverse outdoor scenarios and maintaining accuracy over long distances. -->

- **[Stereo Visual Odometry Using UTIAS Dataset](https://github.com/yourusername/stereo-vo-utias)**:
  
  A stereo visual odometry system using the UTIAS dataset. Emphasizes robust feature extraction, bundle adjustment and motion estimation. 

- **[Feature Tracker Using ICP Algorithm for Event-based Pose Estimation](https://github.com/yourusername/event-based-feature-tracker)**:
  
  A feature tracking system for event-based cameras using the ICP algorithm. Enables pose estimation in high-speed and high-dynamic range scenarios. 
  <!-- Focuses on efficient processing of asynchronous event data and handling rapid motions. -->

- **[Camera Calibration, Pose Estimation, and AR using Aruco Markers](https://github.com/yourusername/aruco-pose-estimation)**:
  
  A system for camera calibration, pose estimation, and AR using Aruco markers. Implements marker detection and tracking algorithms in C++. 
  <!-- Addresses challenges in achieving real-time performance and handling marker occlusions. -->

- **[Underwater Image Analysis and Registration](https://github.com/yourusername/underwater-image-analysis)**:
  
  Techniques for analyzing and registering underwater images. Implements methods for color correction, visibility enhancement, and feature matching. 
  <!-- Tackles issues related to light attenuation, scattering, and low contrast in underwater environments. -->

- **[Epipolar Geometry and Stereo Vision Implementation](https://github.com/yourusername/epipolar-stereo-vision)**:
  
  Implementation of epipolar geometry and stereo vision algorithms. Covers camera calibration, rectification, disparity computation, and 3D reconstruction. 
  <!-- Addresses challenges in achieving accurate depth estimation and handling occlusions. -->

## AI and Machine Learning

- **[Explainable AI Module for Interpreting Object Detection Models](https://github.com/yourusername/xai-object-detection)**:
  
  An explainable AI module for object detection models in skin lesion detection. Implements local and global attribution techniques like Grad-CAM, SmoothGrad and LRP for generating explanations. Focuses on improving model interpretability in critical applications. 

- **[Pigmented Skin Lesion Detection Using Deep Learning](https://github.com/adeola-jo/Pigmented-Skin-Lesion-Detection-in-Clinical-Images-Using-Deep-Learning-Methodologies)** [![Results](https://img.shields.io/badge/Code-blue)](https://github.com/yourusername/quadcopter-pid-controller) [![Slides](https://img.shields.io/badge/Slides-yellow)](https://docs.google.com/presentation/d/1wfT9RNvPZfri0lPkou_O2XtTunm7fqA9/edit?usp=sharing&ouid=112754114270272007780&rtpof=true&sd=true) [![Paper](https://img.shields.io/badge/Paper-green)](https://drive.google.com/file/d/19WZi2HKYbNnWiBjFU6UAmOkSPnP7hWEd/view?usp=drive_link) :
  
  A deep learning model for detecting pigmented skin lesions in clinical images. Utilizes transfer learning and data augmentation techniques. Addresses challenges in working with limited medical imaging datasets.
   <!-- and achieving high sensitivity. -->

- **[Semantic Segmentation of Pigmented Skin Lesions](https://github.com/yourusername/skin-lesion-segmentation)**:
  
  A semantic segmentation model for pigmented skin lesions. Adapts the U-Net architecture for precise lesion delineation. Tackles issues in handling irregular lesion shapes and achieving high boundary accuracy.

- **[Deep Learning Based Sentiment Analysis on SST Dataset](https://github.com/yourusername/sst-sentiment-analysis)**:
  
  A sentiment analysis model using the Stanford Sentiment Treebank dataset. Explores RNN, GRU, LSTM and transformer-based architectures. 
  <!-- Addresses challenges in capturing context and handling nuanced language expressions. -->

- **[Similarity Learning Using Metric Embedding](https://github.com/adeola-jo/Metric-Embedding-Similarity-Learning)**  [![Code](https://img.shields.io/badge/Code-blue)](https://github.com/adeola-jo/Metric-Embedding-Similarity-Learning):
  
  A similarity learning system using metric embedding techniques. Focuses on learning embeddings for complex data types like images and text. Tackles challenges in preserving semantic relationships in the embedding space.

- **[Hand-written Digit Classification on MNIST Dataset](https://github.com/yourusername/mnist-classification)**:
  
  A machine learning model for classifying hand-written digits. Compares various neural network architectures and optimization techniques. Addresses issues in handling variations in handwriting styles and achieving high accuracy.

- **[Image Classification on CIFAR Dataset](https://github.com/adeola-jo/CNN-Image-Classification)**  [![Code](https://img.shields.io/badge/Code-blue)](https://github.com/adeola-jo/CNN-Image-Classification):
  
  Deep learning models for image classification using the CIFAR dataset. Explores techniques like batch normalization and dropout. Focuses on balancing model complexity with computational efficiency.

- **[Facial Expression Recognition using Transfer Learning](https://github.com/yourusername/facial-expression-recognition)**:
  
  A facial expression recognition system using transfer learning with ResNet-18. Optimized for real-time performance on edge devices. Addresses challenges in handling varying lighting conditions and facial orientations.

## SLAM and Localization

- **[Pose-based EKF SLAM using ICP for Scan Registration](https://github.com/adeola-jo/Pose-Based-EKF-SLAM-ICP)** [![Code](https://img.shields.io/badge/Code-blue)](https://github.com/adeola-jo/Pose-Based-EKF-SLAM-ICP) [![Video](https://img.shields.io/badge/Video-orange)](https://drive.google.com/file/d/1PEf_F3UzkBr-r8IKw35gX7s7DPliBYtB/view) [![Slides](https://img.shields.io/badge/Slides-yellow)](https://drive.google.com/file/d/1JyMfuOR27wxJiWWq6XvO4kKM0-gFEU43/view) [![Paper](https://img.shields.io/badge/Paper-green)](https://drive.google.com/file/d/1oSkCsCm-WVmKDD7IK5GAbs2VEl246Cdo/view): EDIT CODE README
  
  An EKF-SLAM system integrated with ICP scan-matching. Uses 2D LiDAR and IMU sensors for localization and mapping. Tackles challenges in handling sensor uncertainties and achieving real-time performance in small environments.

- **[An EKF SLAM of Kobuki Turtlebot Using Point Beacons in a Simulation Environment](https://github.com/yourusername/ekf-turtlebot-simulation)** [![Video](https://img.shields.io/badge/Video-orange)](https://yourvideo-link.com) [![Code](https://img.shields.io/badge/Code-blue)](https://github.com/yourusername/ekf-turtlebot-simulation) [![Report](https://img.shields.io/badge/Report-green)](https://yourreport-link.com):

  An EKF SLAM system for the Kobuki Turtlebot using point beacons in a simulation environment. Implements point beacon detection and mapping for localization. Tackles challenges in maintaining accuracy and robustness in a simulated setup.

- **[EKF Map-Based Localization Using Line Feature in a Simulation Environment](https://github.com/adeola-jo/Line-Feature-EKF-Map-Localization)** [![Code](https://img.shields.io/badge/Code-blue)](https://github.com/adeola-jo/Line-Feature-EKF-Map-Localization) :

  An EKF map-based localization system using line features in a simulation environment. Implements line feature extraction and map-based localization. Focuses on improving localization accuracy and robustness in simulated conditions.


<!-- - **[Feature-based SLAM Using Monocular Camera and Aruco Markers](https://github.com/yourusername/monocular-slam-aruco)**: -->
  
  <!-- A feature-based SLAM system using a monocular camera and Aruco markers. Implements efficient landmark detection and data association.  -->
  <!-- Addresses issues in scale ambiguity and loop closure detection. -->


  <!-- Focuses on handling challenging outdoor environments and maintaining long-term consistency. -->

- **[Particle Filter Algorithm for Kobuki Turtlebot Localization](https://github.com/adeola-jo/Robot-Localization-Particle-Filter)** [![Code](https://img.shields.io/badge/Code-blue)](https://github.com/adeola-jo/Robot-Localization-Particle-Filter) :
  
  A particle filter-based localization system for the Kobuki Turtlebot. Implements efficient particle sampling and resampling strategies. 
  <!-- Addresses challenges in achieving real-time performance and handling dynamic obstacles. -->

## Motion Planning and Autonomous Systems

- **[Autonomous Frontier-Based Robot Exploration and Path Planning](https://github.com/yourusername/frontier-rrt-exploration)** [![Video (Real)](https://img.shields.io/badge/Video%20(Real)-orange)](https://yourvideo-link.com) [![Video (Simulation)](https://img.shields.io/badge/Video%20(Simulation)-orange)](https://yourvideo-link.com) [![Slides](https://img.shields.io/badge/Slides-yellow)](https://yourslides-link.com) [![Report](https://img.shields.io/badge/Report-green)](https://yourreport-link.com):
  
  An autonomous exploration system combining Frontier-Based exploration with RRT* path planning. Implements the Dynamic Window approach for robot control. Tackles challenges in efficiently exploring unknown environments and avoiding local minima.

- **[Robot Pick and Place Task Using PDDL AI-Planner](https://github.com/adeola-jo/AI-Planning)** [![Code](https://img.shields.io/badge/Code-blue)](https://github.com/adeola-jo/AI-Planning) [![Slides](https://img.shields.io/badge/Slides-yellow)](https://drive.google.com/file/d/12yXTfvdvCOjZsD0cYZsoodCp_eP4nlte/view?usp=sharing):
  
  A pick and place system using PDDL (Planning Domain Definition Language) for task planning. Generates optimal action sequences for multi-object manipulation. Addresses challenges in translating high-level plans to robot actions.


- **[Reinforcement Learning-Based Path Planning for Autonomous Robots in Static Environments](https://github.com/adeola-jo/Reinforcement-Learning)** [![Code](https://img.shields.io/badge/Code-blue)](https://github.com/adeola-jo/Reinforcement-Learning) [![Video](https://img.shields.io/badge/Video-orange)](https://drive.google.com/file/d/1uTSyRr9wZ97qH6WT5faLlAshhQAb7DuN/view) [![Report](https://img.shields.io/badge/Report-green)](https://drive.google.com/file/d/15DA3ioxrJmgj3Xvvlptyq7Ff3k1GnVyh/view?usp=sharing):
  
  A reinforcement learning approach for robot path planning. Utilizes Q-learning method. Focuses on training agents to navigate efficiently in complex environments with obstacles.

- **[Implementation of Bicycle Model, Potential Function, BrushFire, Rotational Plane Sweep, A*, RRT, and RRT* Motion Planning Algorithms](https://github.com/adeola-jo/Motion-Planners)** ![Confidential](https://img.shields.io/badge/Confidential-red):
  
  Implementations of key motion planning algorithms: Potential Functions, BrushFire, Rotational Plane Sweep, A*, RRT, and RRT*. These methods provide diverse strategies for robotic pathfinding and obstacle navigation, suitable for various environments. The code is confidential due to its development as part of the Intelligent Field Robotics Systems Erasmus Master's program and includes proprietary contributions from the University of Girona not intended for public dissemination without permission.


  <!-- Conducts performance analysis in various environments. Addresses trade-offs between computational efficiency and path optimality. -->

- **[Autonomous Exploration, Localization, Mapping, Perception, and Manipulation](https://github.com/yourusername/autonomous-robot-system)** [![Simulation Demo](https://img.shields.io/badge/Simulation%20Demo-purple)](https://drive.google.com/file/d/1LZKQDQFDvICbNO9TPoZ9PdlU2wQQhSYe/view) [![Real World Demo](https://img.shields.io/badge/Real%20World%20Demo-cyan)](https://drive.google.com/file/d/1V2GTVkTomQQViEsOUmajFos93Ll_3ju4/view):
  
  An integrated system for autonomous robot operation. Combines exploration, SLAM, perception, and manipulation capabilities. Tackles challenges in coordinating multiple subsystems for end-to-end autonomy.


## Multi-Robot Systems and Swarm Robotics

- **[Controlling a Swarm of Omnidirectional Robots Using Reynolds' Rules](https://adeola-jo.github.io/multirobotswarm/)** [![Website](https://img.shields.io/badge/Website-purple)](https://adeola-jo.github.io/multirobotswarm/) [![Code](https://img.shields.io/badge/Code-blue)](https://github.com/KhAlamdar11/ReynoldsSwarmSim) [![Demo Videos](https://img.shields.io/badge/Demo%20Videos-orange)](https://drive.google.com/drive/folders/1_SvOxjlmt7w-MyqUQo5wPxWnhk7myUXQ) [![Slides](https://img.shields.io/badge/Slides-yellow)](https://docs.google.com/presentation/d/1aDjviKdi5GM9d_JgCk9qEbm-q0vmppn6QXxR2qgRIuA/edit) [![Paper](https://img.shields.io/badge/Paper-green)](https://drive.google.com/file/d/1AU1p8NbJkrCIrgaVI7rVj1MP6kr288h8/view):
  
  Implementation of Reynolds' flocking rules for a group of omnidirectional robots. Applies principles of separation, alignment, and cohesion to achieve collective behavior. Tackles issues in distributed control and scalability to larger swarms.

- **[Multi-Modal Human-Swarm Interaction](https://github.com/yourusername/multimodal-swarm-interaction)** [![Demo Videos](https://img.shields.io/badge/Demo%20Videos-orange)](https://drive.google.com/drive/folders/1XM-vsduA-TXC_88UCu2qsBz0QXbR68oI) [![Slides](https://img.shields.io/badge/Slides-yellow)](https://docs.google.com/presentation/d/1ZfhdezTUXDK6KagSSJFdSf0vnmEyWE0-/edit) [![Paper](https://img.shields.io/badge/Paper-green)](https://drive.google.com/file/d/1h6QMTAdxbi3cnmJCeh4XR5vvBq08i8Fl/view):
  
  A system for human-swarm interaction using vision, speech, and multi-agent language models. Enables natural command and control of robot swarms. Addresses challenges in interpreting high-level instructions for swarm behavior.

- **[Robust Coordination and Control of Multi-Robot Systems Using Consensus Protocols](https://github.com/MosesEbere/multi-robot-consensus)** [![Code](https://img.shields.io/badge/Code-blue)](https://github.com/MosesEbere/multi-robot-consensus) [![Demo Videos](https://img.shields.io/badge/Demo%20Videos-orange)](https://drive.google.com/drive/folders/1agy1DhuncM1e3GaY_0MPgrjashzZ6VJX) [![Slides](https://img.shields.io/badge/Slides-yellow)](https://docs.google.com/presentation/d/1cV9Jt40W_MQDQxBjrlPGlVbbfcr-4xamPMJFvkyeBgM/edit) [![Paper](https://img.shields.io/badge/Paper-green)](https://drive.google.com/file/d/1a99lHnJxuzCbdavcXC3tj0-So__Mk99p/view):
  
  Consensus protocol-based control strategies for multi-robot systems. Focuses on rendezvous and formation control using graph theory. Tackles issues in distributed control and scalability in various network topologies.

- **[ROS Package for Spawning Multiple Robots in Gazebo](https://github.com/MosesEbere/gazebo_multi_robot_spawn)** [![Code](https://img.shields.io/badge/Code-blue)](https://github.com/MosesEbere/gazebo_multi_robot_spawn):
  
  A ROS package for spawning and managing multiple robots in Gazebo. Addresses challenges in efficiently simulating large-scale homogeneous multi-robot systems.